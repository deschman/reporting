2021-02-19 17:01:22,361 MainThread DEBUG: Creating backup dir at 'C:\Users\deschman\spyder-env\Lib\site-packages\reportio\_backup'
2021-02-19 17:01:22,361 MainThread INFO: Creating temp dir at 'C:\Users\deschman\spyder-env\Lib\site-packages\reportio\_temp_files'
2021-02-19 17:01:22,361 MainThread INFO: Starting report with new log located at 'C:\Users\deschman\spyder-env\Lib\site-packages\reportio\log.txt'
2021-02-19 17:01:22,369 MainThread DEBUG: Variables:
                     dirSelf: 'C:\Users\deschman\spyder-env\Lib\site-packages\reportio'
                     log_location: 'C:\Users\deschman\spyder-env\Lib\site-packages\reportio\log.txt'
                     config_location: 'c:\users\deschman\spyder-env\lib\site-packages\reportio\templates\config.txt'
2021-02-19 17:01:22,379 MainThread DEBUG: Checking for backup files
2021-02-19 17:01:22,379 MainThread DEBUG: No backup found
2021-02-19 17:01:22,379 MainThread DEBUG: Adding row to metadata with:
                         query_name: Category
                         sql: SELECT * FROM CATEGORY
                         db_type: sqlite
                         connection: None
                         db_location: 
2021-02-19 17:01:22,389 MainThread DEBUG: Adding row to metadata with:
                         query_name: Subcategory
                         sql: SELECT * FROM SUB_CATEGORY
                         db_type: sqlite
                         connection: None
                         db_location: 
2021-02-19 17:01:22,389 MainThread DEBUG: Adding row to metadata with:
                         query_name: Segment
                         sql: SELECT * FROM SEGMENT
                         db_type: sqlite
                         connection: None
                         db_location: 
2021-02-19 17:01:22,619 MainThread INFO: Running with multithreading
2021-02-19 17:01:22,619 MainThread CRITICAL: See log for debug details
Traceback (most recent call last):
  File "c:\users\deschman\spyder-env\lib\site-packages\distributed\worker.py", line 3398, in dumps_function
    result = cache_dumps[func]
  File "c:\users\deschman\spyder-env\lib\site-packages\distributed\utils.py", line 1512, in __getitem__
    value = super().__getitem__(key)
  File "C:\ProgramData\Miniconda3\lib\collections\__init__.py", line 1010, in __getitem__
    raise KeyError(key)
KeyError: <bound method SimpleReport.export_data of <reportio.templates.simple.SimpleReport object at 0x000001FE8C2C3610>>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\deschman\spyder-env\lib\site-packages\distributed\protocol\pickle.py", line 49, in dumps
    result = pickle.dumps(x, **dump_kwargs)
AttributeError: Can't pickle local object 'SimpleReport.__init__.<locals>._define_optional_functions.<locals>._backup_metadata'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\deschman\spyder-env\lib\site-packages\reportio\templates\simple.py", line 397, in run
    export_locations = _process_queries(multithread,
  File "c:\users\deschman\spyder-env\lib\site-packages\reportio\templates\simple.py", line 376, in _process_queries
    export_locations.compute()))
  File "c:\users\deschman\spyder-env\lib\site-packages\dask\base.py", line 281, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "c:\users\deschman\spyder-env\lib\site-packages\dask\base.py", line 563, in compute
    results = schedule(dsk, keys, **kwargs)
  File "c:\users\deschman\spyder-env\lib\site-packages\distributed\client.py", line 2635, in get
    futures = self._graph_to_futures(
  File "c:\users\deschman\spyder-env\lib\site-packages\distributed\client.py", line 2543, in _graph_to_futures
    dsk = highlevelgraph_pack(dsk, self, keyset)
  File "c:\users\deschman\spyder-env\lib\site-packages\distributed\protocol\highlevelgraph.py", line 115, in highlevelgraph_pack
    "state": _materialized_layer_pack(
  File "c:\users\deschman\spyder-env\lib\site-packages\distributed\protocol\highlevelgraph.py", line 68, in _materialized_layer_pack
    dsk = valmap(dumps_task, dsk)
  File "c:\users\deschman\spyder-env\lib\site-packages\toolz\dicttoolz.py", line 83, in valmap
    rv.update(zip(d.keys(), map(func, d.values())))
  File "c:\users\deschman\spyder-env\lib\site-packages\distributed\worker.py", line 3436, in dumps_task
    return {"function": dumps_function(task[0]), "args": warn_dumps(task[1:])}
  File "c:\users\deschman\spyder-env\lib\site-packages\distributed\worker.py", line 3400, in dumps_function
    result = pickle.dumps(func, protocol=4)
  File "c:\users\deschman\spyder-env\lib\site-packages\distributed\protocol\pickle.py", line 60, in dumps
    result = cloudpickle.dumps(x, **dump_kwargs)
  File "c:\users\deschman\spyder-env\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 73, in dumps
    cp.dump(obj)
  File "c:\users\deschman\spyder-env\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 563, in dump
    return Pickler.dump(self, obj)
TypeError: cannot pickle '_asyncio.Task' object
2021-02-19 17:01:22,662 MainThread WARNING: Backing up data
2021-02-19 17:01:22,662 MainThread DEBUG: Backup location: C:\Users\deschman\spyder-env\Lib\site-packages\reportio\_backup
2021-02-19 17:01:22,662 MainThread DEBUG: Backing up metadata to 'C:\Users\deschman\spyder-env\Lib\site-packages\reportio\_backup\__Metadata.xlsx'
2021-02-19 17:01:22,699 MainThread INFO: Backup successful
2021-02-19 17:01:27,209 MainThread INFO: QUITTING
2021-02-19 17:02:06,669 MainThread INFO: Starting report with existing log located at 'C:\Users\deschman\spyder-env\Lib\site-packages\reportio\log.txt'
2021-02-19 17:02:06,669 MainThread DEBUG: Variables:
                     dirSelf: 'C:\Users\deschman\spyder-env\Lib\site-packages\reportio'
                     log_location: 'C:\Users\deschman\spyder-env\Lib\site-packages\reportio\log.txt'
                     config_location: 'c:\users\deschman\spyder-env\lib\site-packages\reportio\templates\config.txt'
2021-02-19 17:02:06,669 MainThread INFO: Removing C:\Users\deschman\spyder-env\Lib\site-packages\Yearly Sales.xlsx
2021-02-19 17:02:06,830 MainThread DEBUG: Checking for backup files
2021-02-19 17:02:06,830 MainThread INFO: Resuming previous attempt
2021-02-19 17:02:06,830 MainThread DEBUG: These files will be read from backup: []
2021-02-19 17:02:06,830 MainThread DEBUG: Adding row to metadata with:
                         query_name: Category
                         sql: SELECT * FROM CATEGORY
                         db_type: sqlite
                         connection: None
                         db_location: 
2021-02-19 17:02:06,839 MainThread DEBUG: Adding row to metadata with:
                         query_name: Subcategory
                         sql: SELECT * FROM SUB_CATEGORY
                         db_type: sqlite
                         connection: None
                         db_location: 
2021-02-19 17:02:06,839 MainThread DEBUG: Adding row to metadata with:
                         query_name: Segment
                         sql: SELECT * FROM SEGMENT
                         db_type: sqlite
                         connection: None
                         db_location: 
2021-02-19 17:02:06,889 MainThread INFO: Running with multithreading
2021-02-19 17:02:06,909 MainThread CRITICAL: See log for debug details
Traceback (most recent call last):
  File "c:\users\deschman\spyder-env\lib\site-packages\dask\local.py", line 436, in get_async
    start_state(dsk, state)
  File "c:\users\deschman\spyder-env\lib\site-packages\reportio\future\tqdm\dask.py", line 30, in _start_state
    self.pbar = self.tqdm_class(total=sum(
  File "c:\users\deschman\spyder-env\lib\site-packages\reportio\future\tqdm\notebook.py", line 231, in __init__
    self.container = self.status_printer(
  File "c:\users\deschman\spyder-env\lib\site-packages\reportio\future\tqdm\notebook.py", line 96, in status_printer
    raise ImportError(
ImportError: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\deschman\spyder-env\lib\site-packages\reportio\templates\simple.py", line 397, in run
    export_locations = _process_queries(multithread,
  File "c:\users\deschman\spyder-env\lib\site-packages\reportio\templates\simple.py", line 376, in _process_queries
    export_locations.compute()))
  File "c:\users\deschman\spyder-env\lib\site-packages\dask\base.py", line 281, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "c:\users\deschman\spyder-env\lib\site-packages\dask\base.py", line 563, in compute
    results = schedule(dsk, keys, **kwargs)
  File "c:\users\deschman\spyder-env\lib\site-packages\dask\threaded.py", line 76, in get
    results = get_async(
  File "c:\users\deschman\spyder-env\lib\site-packages\dask\local.py", line 502, in get_async
    finish(dsk, state, not succeeded)
  File "c:\users\deschman\spyder-env\lib\site-packages\reportio\future\tqdm\dask.py", line 37, in _finish
    self.pbar.close()
AttributeError: 'TqdmCallback' object has no attribute 'pbar'
2021-02-19 17:02:06,919 MainThread WARNING: Backing up data
2021-02-19 17:02:06,919 MainThread DEBUG: Backup location: C:\Users\deschman\spyder-env\Lib\site-packages\reportio\_backup
2021-02-19 17:02:06,919 MainThread DEBUG: Backing up metadata to 'C:\Users\deschman\spyder-env\Lib\site-packages\reportio\_backup\__Metadata.xlsx'
2021-02-19 17:02:06,959 MainThread INFO: Backup successful
2021-02-19 17:02:18,129 MainThread INFO: QUITTING
2021-02-19 17:11:23,958 MainThread INFO: Starting report with existing log located at 'C:\Users\deschman\spyder-env\Lib\site-packages\reportio\log.txt'
2021-02-19 17:11:23,958 MainThread DEBUG: Variables:
                     dirSelf: 'C:\Users\deschman\spyder-env\Lib\site-packages\reportio'
                     log_location: 'C:\Users\deschman\spyder-env\Lib\site-packages\reportio\log.txt'
                     config_location: 'c:\users\deschman\spyder-env\lib\site-packages\reportio\templates\config.txt'
2021-02-19 17:11:23,958 MainThread INFO: Removing C:\Users\deschman\spyder-env\Lib\site-packages\Yearly Sales.xlsx
2021-02-19 17:11:24,158 MainThread DEBUG: Checking for backup files
2021-02-19 17:11:24,158 MainThread INFO: Resuming previous attempt
2021-02-19 17:11:24,158 MainThread DEBUG: These files will be read from backup: []
2021-02-19 17:11:24,158 MainThread DEBUG: Adding row to metadata with:
                         query_name: Category
                         sql: SELECT * FROM CATEGORY
                         db_type: sqlite
                         connection: None
                         db_location: 
2021-02-19 17:11:24,158 MainThread DEBUG: Adding row to metadata with:
                         query_name: Subcategory
                         sql: SELECT * FROM SUB_CATEGORY
                         db_type: sqlite
                         connection: None
                         db_location: 
2021-02-19 17:11:24,158 MainThread DEBUG: Adding row to metadata with:
                         query_name: Segment
                         sql: SELECT * FROM SEGMENT
                         db_type: sqlite
                         connection: None
                         db_location: 
2021-02-19 17:11:24,218 MainThread INFO: Running with multithreading
2021-02-19 17:11:24,228 Thread-10 DEBUG: Querying database
2021-02-19 17:11:24,228 Thread-11 DEBUG: Querying database
2021-02-19 17:11:24,228 Thread-12 DEBUG: Querying database
2021-02-19 17:11:24,228 MainThread CRITICAL: See log for debug details
Traceback (most recent call last):
  File "c:\users\deschman\spyder-env\lib\site-packages\reportio\templates\simple.py", line 399, in run
    export_locations = _process_queries(multithread,
  File "c:\users\deschman\spyder-env\lib\site-packages\reportio\templates\simple.py", line 378, in _process_queries
    export_locations.compute()))
  File "c:\users\deschman\spyder-env\lib\site-packages\dask\base.py", line 281, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "c:\users\deschman\spyder-env\lib\site-packages\dask\base.py", line 563, in compute
    results = schedule(dsk, keys, **kwargs)
  File "c:\users\deschman\spyder-env\lib\site-packages\dask\threaded.py", line 76, in get
    results = get_async(
  File "c:\users\deschman\spyder-env\lib\site-packages\dask\local.py", line 487, in get_async
    raise_exception(exc, tb)
  File "c:\users\deschman\spyder-env\lib\site-packages\dask\local.py", line 317, in reraise
    raise exc
  File "c:\users\deschman\spyder-env\lib\site-packages\dask\local.py", line 222, in execute_task
    result = _execute_task(task, data)
  File "c:\users\deschman\spyder-env\lib\site-packages\dask\core.py", line 121, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "c:\users\deschman\spyder-env\lib\site-packages\reportio\templates\__init__.py", line 538, in get_data
    temporary_dataframe: pd.DataFrame = pd.read_sql(
  File "c:\users\deschman\spyder-env\lib\site-packages\pandas\io\sql.py", line 484, in read_sql
    return pandas_sql.read_query(
  File "c:\users\deschman\spyder-env\lib\site-packages\pandas\io\sql.py", line 1743, in read_query
    cursor = self.execute(*args)
  File "c:\users\deschman\spyder-env\lib\site-packages\pandas\io\sql.py", line 1695, in execute
    cur = self.con.cursor()
AttributeError: 'float' object has no attribute 'cursor'
2021-02-19 17:11:24,238 MainThread WARNING: Backing up data
2021-02-19 17:11:24,238 MainThread DEBUG: Backup location: C:\Users\deschman\spyder-env\Lib\site-packages\reportio\_backup
2021-02-19 17:11:24,238 MainThread DEBUG: Backing up metadata to 'C:\Users\deschman\spyder-env\Lib\site-packages\reportio\_backup\__Metadata.xlsx'
2021-02-19 17:11:24,278 MainThread INFO: Backup successful
2021-02-19 17:12:04,938 MainThread INFO: QUITTING
